#pragma once

#define WIN32_LEAN_AND_MEAN // 거의 사용되지 않는 내용을 Windows 헤더에서 제외합니다.

#include "CorePch.h"

/*
함수 호출 규약
1. __stdcall 
함수가 호출되어 인자를 전달할 때 스택을 이용해서 전달한다.
스택에 인자의 오른쪽을 시작으로 해서 왼쪽까지 스택에 순서대로 넣고 함수 처리가 끝난 후 스택에 있던 인자들을
(호출 당함 함수) 에서 모두 해제를 하고 반환한다.
스택에 인자를 넣고 -> 함수 호출 -> 함수 처리가 끝난 후 스택의 인자를 해제(스택복원) -> 함수 반환

2. __cdecl
(호출한 함수)에서 스택에 있던 인자를 해제한다.
스택에 인자를 넣고 -> 함수 호출 -> 함수 반환 -> 호출한 함수로 돌아온 후 스택의 인자를 해체

3. __fastcall
두 개의 인자를 레지스터 ecs와 edx를 이용해 전달하는 방식
스택에 인자를 넣는데 2개의 인자에 대해서는 레지스터가 비어있다면 레지스터로 넣는다 -> 함수 호출 -> 함수 처리가
끝난 후 스택의 인자를 해제(스택복원) -> 함수 반환

4. __thiscall
인자 전달 방식이나 해제 방식은 __stdcall과 같다.
this라는 인자를 ecx 레지스터에 전달한다. ( 클래스 )
클래스는 같은 형태로 여러 개의 객체를 만들 수 있는데 이 각각의 객체들은 멤버 변수와 멤버 함수?를 가지며 
이 객체들의 멤버 변수는 메모리 상에서도 서로 다른 위치에서 독립적이다.
멤버 함수는 메모리상에 같은 위치에 있어서 모든 객체들은 같은 멤버 함수를 이용한다.
그렇지만 멤버 함수에서는 각각의 객체에 해당하는 멤버 변수들을 특별한 선언 없이도 접근이 가능해야 하기 때문에
그것을 하기 위해 this라는 객체 자신의 포인터가 필요하다.
스택에 인자를 넣고 this 포인터를 ecx 레지스터에 넣는다. -> 함수 호출 -> 함수 처리가 끝난 후 스택의 인자를 해제
(스택복원) -> 함수 반환
*/

/*
Scatter-Gatter I/O
WSASend() 함수를 이용하여 여러 개의 패킷를 하나의 버퍼러 묶어 보내고 
받는 쪽에서는 WSARecv()함수를 이용하여 하나의 패킷으로 받아서 다시 여러 개의 패킷으로 나눌 수 있다.
*/

/*
Overlapped I/O
중첩 입출력
1. 비동기 데이터를 송수신 할 수 있다.
2. 소켓 내부 버퍼를 사용하지 않고 직접 TCP 전송 버퍼에서 데이터를 보내고 받을 수 있다.

1.
send()나 recv() 와의 차이
데이터 송수신 때 우리는 다른 일을 할 수 있는 것이 아니라 send() 나 recv() 함수로 데이터를 송수신 해야 
그 데이터를 가져올 수 있다.
하지만 Overlapped I/O에서는 커널에 데이터를 송수신 하겠다고 요청을 하고나서 우리가 따로 데이터를 송수신 할
필요가 없다.
우리가 데이터를 송수신하고 있는 동시에 다른 일을 할 수 있느냐 없느냐의 차이

동시에 여러 개의 데이터 송수신을 요청할 수 있다.
데이터 송수신을 커널에 요청한 후에 즉 커널에 데이터 송수신을 맡긴 후 우리는 다른 일을 할 수 있다.
그 다른 일이 또다시 데이터 송수신 하는 일일수도 있다.
이럴 때 우리는 이전 데이터 송수신 작업의 완료와 관계없이 또 다른 데이터 송수신 작업을 커널에 요청 할 수 있다.

2.
소켓 옵션 함수를 이용하여 소켓 내부 버퍼를 0으로 만들어 주어야 가능하다.
다시 봅시다

*/

/*
I/O Completion Port
- Overlapped I/O에 스레드 풀링 + Queue라는 메커니즘을 동시에 접목 시킨 모델
- 스레드 풀이란 스레드를 모아 놓는 곳 ( 여러 개의 스레드를 대기 상태로 미리 생성해 놓은 것 )
- 스레드 풀링 : 스레드 풀에서 대기 중인 스레드들 중에 현재 필요한 만큼 꺼내어 실행 상태로 바꾸어 사용하고 다 사용한 스레드는 파괴하지 않고 다시 대기 상태로 바꿔서 스레드 풀에 넣어주는 과정
- 스레드 생성과 파괴에 따른 CPU 소모를 줄이기 위해 -> CPU의 시간 ( 타임 슬라이스 ) 을 낭비하지 않고 다른 일을 할 수 있기 때문
- 스레드에서 다른 스레드로 작업 전환을 할 때에 컨텍스트 스위칭이란 작업이 발생하는데 컨텍스트 스위칭 또한 CPU 소모가 많아 자주 일어나면 성능이 떨어진다.

과정
- CreateIoCompletionPort() 함수를 이용해 Socket과 CompletionKey를 CompletionPort라는 개체에 등록 시킨다.
- 완료된 작업의 결과를 받을 떄 GetQueuedCompletionStatus() 함수를 이용한다.
- CreateIoCompletionPort() 함수를 이용해 CompletionPort 객체에 등록한 Socket과 Completionkey를 관리하는 Device List라는 자료 구조가 추가되었다.
- Device List는 CompltionPort 객체에 등록된 Device를 관리해 주는 역할 -> 여기서는 Socket이다
- IOCP Queue(I/O Completion Port Queue)라는 자료 구조의 추가다
- 이전 Overlapped 모델은 요청한 작업이 완료가 되면 곧바로 사용자에게 그 결과를 이벤트나 콜백 함수에 의해 알렸다.
- 그러나 이 모델은 커널이 우리가 요청한 Overlapped I/O작업이 완료 되었을 때 곧바로 사용자에게 알리지 않고 완료된 작업 결과를 IOCP Queue에 넣은 후
- CompltionPort 객체를 이용해 사용자에게 알린다.
- 커널은 스레드 풀링 매커니즘을 이용하여 IOCP Queue에서 완료된 Overlapped I/O작업을 가져와 뒤 처리를 한다.
- IOCP Queue에 완료된 작업 결과가 들어오면 WatingThread Queue (LIFO) 에서 대기하고 있떤 스레드들 중 가장 나중에 추가된 몇 개를 실행 상태로 만들고
- WatingThread Queue에서 삭제한 수 ReleaseThread List에 추가한다.
- 그리고 실행 상태로 바뀐 스레드들은 IOCP Queue에서 완료된 작업 결과를 가져와 유저 모드의 GetQueuedCompletionStatus() 함수로 반환하고 완료된 작업의 뒤 처리를 계속해서 한다.
- 다음으로 실행 상태가 된 스레드들은 완료된 작업의 뒤 처리를 하는데 만약 뒤 처리 중 대기 작업을 하는 함수를 호출하면 해당 스레드는 대기 상태로 바뀌고 ReleaseThread List
- 에서 삭제된 후 PausedThread List에 추가된다.
- 뒤처리 중 대기 상태로 들어간 스레드가 후에 다시 실행 상태가 된다면 PausedThread List에서 삭제된 후 ReleaseThread List로 추가되고 이전에 작업을 뒤이어 한다.
- 그리고 모든 처리 과정을 마친 후 다시 GetQueuedCompletionStatus() 함수를 호출한다.
- IOCP Queue에 완료된 작업이 있으면 위에 과정을 반복하고 완료된 작업이 없다면 스레드는 대기 상태로 바뀌고 ReleaseThread List에서 삭제된 후 WatingThread Queue로 들어가게 된다.
- WaitingThread Queue의 입출력 순서가 LIFO다.
- 컨텍스트 스위칭을 피하기 위해서다
- 예를 들어 실행 상태에 있던 A스레드가 처리를 마치고 GetQueuedCompletionStatus() 함수에 의해 다시 대기 상태가 되어서 WatingThread Queue에 들어왔다.
- 그런데 이 때 IOCP Queue에 완료된 작업이 들어와 WatingThread Queue에 대기 하고 있던 스레드들 중 가장 마지막에 들어온 A스레드가 실행 상태로 다시 바뀐다면
- 컨텍스트 스위칭이 일어나지 않을 것이다.
- 왜냐하면 컨텍스트 스위칭은 서로 다른 스레드간의 전환이 일어나는 것인데 여기에서는 대기 상태였던 스레드를 다시 실행 상태로 바뀌었을 뿐 다른 스레드간의 전환은 일어나지 않는다.

- 커널은 동시에 실행 상태가 되는 스레드의 개수가 부족하면 스레드 풀에서 대기 중인 스레드들을 꺼내서 실행 상태로 만들고 초과할 떄는 대기 상태로 만들어서
- 다시 스레드 풀에 넣어주는 역할을 하여 동시에 실행 상태에 있는 스레드 개수를 사용자가 설정한 일정 개수로 유지될 수 있도록 조절하고 있다.

- WatingThread Queue에 대기 중인 스레드가 충분해야 한다.
- 실행 상태에 있던 스레드가 완료된 작업의 뒤 처리를 하고 있는 중 대기 작업 함수를 호출하였다면 그 스레드는 ReleaseThread List에서 삭제된 후 
- 대기 작업 함수를 끝날떄 까지 PauseThread List에서 대기 상태로 기다리고
- WatingThread Queue에서 대기 중인 다른 스레드가 실행 상태로 바뀐다.
- 근데 만약 WatingThread Queue에 대기 중인 스레드가 없다면 사용자가 설정한 동시에 실행 중인 스레드 개수가 유지 될 수 없어
- 최악의 경우는 실행중인 스르데가 모두 대기 작업 함수를 ㅎ호출하여 실행 상태에 있는 스레드가 없을 수도 있다.

*/

/*
Page-Locking
- IOCP에서 WSASend 혹은 WSARecv할 때 기본적으로 Overlapped I/O 방식으로 I/O를 수행한다.
- WSASend,WSARecv 함수 호출할 때 결과를 기록할 버퍼를 우리가 직접 제공한다 ( WSABUF )
- 이 버퍼는 I/O 과정에서 커널이 직접 접근해서 읽고 쓸 수 있어야 한다.
- 이 때문에 해당 버퍼가 있는 위치의 Physical Memory에는 page-lock이 걸린다.
- 이 부분 메모리는 커널이 계속 쓰거나 읽을 수 있어야하므로 해당 영역이 Page Out 같은게 일어나면 안된다.

Loked Page Limit
- OS 입장에서 이 Page-Locking이 문제가 될 수 있다.
- 만약에 동시에 엄청난 양의 send or recv가 진행되서 physical memory 전체가 락이 걸리면
- os는 다름 프로그램을 실행시킬 수 없게 된다.
- 그래서 os는 Locked Page Limit라는 것을 두었다.
- 한 프로세스가 페이지 락을 걸 수 있는 양에 한계를 둔것이다.
- 대략 램의 8분의1정도다
- 이 제한에 도달하면 IOCP를 사용한 작업들은 ERROR_INSUFFICIENT_RESOURCES 에러 -> 실패

Non-paged pool limit
- non-paged pool 이라는 특별한 영역이 있다.
- 이 영역은 항상 물리적 메모리에 위치해야 하면 , 절대 page-out 되지 않는다.
- 이 영역은 보통 커널이 드라이버 정보 등 다양한 커널 모드 컴포넌트들에게 필요한 정보를 저장한다.
- 문제는 소켓을 생성할 때도 이 풀의 공간을 약간씩 소모한다.
- 만약에 접속자 수가 굉장히 많아지면 이 공간이 가득차서 문제를 일으 킬 수 있다.
- 따라서 최대 세션 개수를 적절히 정해서 그걸 관리하는 방법 밖에 없다

Page-Locking 최소화
- 일단 Lock이 걸리는 단위가 버퍼 크기가 아니라 Page 크기다
- 버퍼를 최대한 페이지 크기에 맞춰서 페이지 공간을 낭비없이 사용하면 좀 더 효율적

Zero byte Recv
- 최대 연결 세션 개수가 중요한 서버에서 쓸 수 있다.
- 0바이트를 읽는 recv 작업을 보내는 기법
- 읽는 크기가 0바이트이기 때문에 recv 작업을 하면서도 page-locking이 일어나지 않는다.
- IOCP는 읽는 크기가 0 바이트라해도 실제 i/o 작업이 일어나기 전짜기 io/completion으로 생각하지 않는다.
- 뭔가 읽기 작업이 일어나면 0바이트 읽었다는 I/O Compltion이 도착하게 되고 이제 다시 이걸 읽어내면 엄청나게 많은 연결에 대한 읽기 작업도 모두 0바이트만
- 갖고 일단 읽기 작어이 일어났는지 확인한 후 , 실제 읽기 작업에 들어 갈 수 있다.
- IOCP는 Proactor 방식이기 때문에 실제 읽기 작업이 일어나지 않고 있어도 WSARecv하고 있어야 한다
- 이 때문에 많은 메모리가 아무 작업도 안하는데 Page-locking이 될 수 있다.
*/


